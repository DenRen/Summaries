7\.  Параллельные вычисления (no end)
========================

## 7.1 Предпочитайте программирование на основе *задач* программированию на основе *потоков*.

Есть два варианта запустить *doAsyncWork* асинхронно:
```cpp
int doAsyncWork ();

std::thread (doAsyncWork);    // Поток

auto fut = std::async (doAsyncWork); // fut = future
```
Преимущества *std::async*:
* Даёт возвращающее значение в вызывающий код
* Есть доступ к исключению, которое бросила функция (в потоках будет *std::terminate*)
* Решает проблему превышения подписки

Бывают ситуации, когда применение *потоков* является более подходящим:
* Вам нужен доступ к *API*, лежащий в основе реализации потоков (*pthreads* или *Windows Threads*)
* Вам требуется возможность оптимизации потоков в вашем приложении
* Вам требуется реализовать поточную технологию, выходящую за рамки *API* параллельных вычислений *C++*

### <center>Следует запомнить</center>
* API *std::thread* не предлагает способа непосредственного получения возвращаемых значений из асинхронно выполняемых функций, и, если такие функции генерируют исключения, программа завершается.
* Программирование на основе потоков требует управления вручную исчерпанием потоков, превышением подписки, балансом загрузки и адаптацией к новым платформам.
* Программирование на основе задач с помощью *std::async* со стратегией запуска по умолчанию решает большинство перечисленных проблем вместо вас.

## 7.2 Если важна асинхронность, указывайте std::launch::async

У *std::async* есть стратегии запуска:
* **Стратегия** *std::launch:async* означает, что *func* должна выполнятся асинхронно, т.е. в другом потоке
* **Стратегия** *std::launch::deferref* означает, что *func* может выполняться только тогда, когда для *фьючерса*, возвращённого *std::async*, вызывается функция-член *get* или *wait*, т.е. выполнение *func* *откладывается* до тех пор, пока не будет выполнен такой вызов. Когда вызываются функции-члены *get* или *wait*, функция *func* выполняется синхронно, т.е. вызывающая функция блокируется до тех пор, пока *func* не завершит работу. Если не вызывается ни *get*, ни *wait*, *func* не выполняется.

Два приведённых вызова имеют один и тот же смысл:
```cpp
auto fut1 = std::async (func);                   // Выполнение func со
                                                    // стратегиейпо умолчанию
                                                 
auto fut2 = std::async (std::launch::async |     // Выполнение func
                         std::launch::deferred,   // асинхронное и отложенное
                         func);
```

У стратегии запуска по умолчанию есть интересные последствия. Для потока *t*, выполняющего приведённую ниже инструкцию, справедливы следующие утверждения:
```cpp
auto fut = std::async (func); // Выполнение func со стратегией запуска по умолчанию
```
* **Невозможно предсказать, будет ли *func* выполняться параллельно с *t***, поскольку выполнение *func* может быть отложено планировщиком.
* **Невозможно предсказать, будет ли *func* выполняться потоком, отличным о того, в котором вызываются функции-члены *get* или *wait* объекта *fut***. Если этот поток - *t*, отсюда вытекает невозможность предсказать, будет ли *func* выполняться потоком, отличным от *t*.
* **Может быть невозможно предсказать, будет ли *func* выполнена вообще**, поскольку может оказаться невозможность гарантировать, что функции-члены *get* или *wait* объекта *fut* будут вызваны на всех путях выполнения программы.

*Локальная память потока* (*thread-local-storage* - *TLS*)

Гибкость стратегии запуска по умолчанию часто плохо комбинируется с использованием переменных *thread_local*.

Также при использовании стратегии запуска по умолчанию мы можем зайти в бесконечный цикл даже не подозревая этого:
```cpp
using namespace std::literals;

void func () {
    std::this_thread::sleep_for (1s);
}

auto future = std::async (func);    // (Концептуально) асинхронное
                                    // выполнение func

while (future.wait_for (100ms) !=   // Цикл до завершения func
       std::future_status::ready)
{
    // ...                          // ... которого никодга не будет!
}

```

Чтобы избегать подобных ситуаций, нужно проверять фьючерс и выяснять, не отложенная ли данная задача:
```cpp
auto future = std::async (func);    // (Концептуально) асинхронное
                                    // выполнение func
if (future.wait_for (0s) ==
    std::future_status::deferred)
{
    // Используем get или wait для синхронного
    // вызова func
} else {
    while (future.wait_for (100ms) !=
       std::future_status::ready)
    {
        // ...                          // func выполняется параллельно
    }
    
    // future выполнен
}
```

Получается *std::async* со стратегией запуска по умолчанию отлично работает, пока выполняются следующие условия:
* Задача не обязана параллельно работать с потоком, вызывающим *get* или *wait*
* Не имеет значения, переменные *thread_local* какого потока читаются или записываются
* Либо гарантируется вызова *get* или *wait* для фьючерса, возвращаемого *std::async*, либо ситуация, когда задача не выполняется совсем, является примелемой
* Код с использованием *wait_for* или *wait_until* учитывает возможность отложенного состояния задачи

Иногда полезно иметь функцию, которая запускает функцию с *std::launch::async*:
```cpp
template <typename F, typename... Ts>
inline
std::future <std::result_of_t <F (Ts...)>>     // С++14 auto
reallyAsync (F&& f, Ts&&... params)
{
    return std::async (
        std::launch::async,
        std::forward <F> (f),
        std::forward <Ts> (params)...
    );
}
```

### <center>Следует запомнить</center>
* Стратегия запуска по умолчанию для *std::async* допускает как асинхронное, так и синхронное выполнение задачи.
* Эта гибкость ведёт к неопределённости при обращении к переменным *thread_local*, к тому, что задача может никогда не быть выполнена, и влияет на логику программы для вызовов *wait* на основе тайм-аутов.
* Если синхронное выполнение задачи критично, указывайте стратегию запуска *std::launch::async*.
































## 7.3 Делайте *std::thread* неподключаемым на всех путях выполнения

Каждый объект *std::thread* может находиться в двух состояниях: *подключаемом* (*joinable*) и *неподключаемом* (*unjoinable*). Подключаемый может или уже выполняется.

Неподключаемые объекты *std::thread*:
* Объекты *std::thread*, созданные конструктором по умолчанию
* Объекты *std::thread*, из которых выполнено перемещение
* Объекты *std::thread*, из которых выполнена функция-член *join*
* Объекты *std::thread*, из которых выполнена функция-член *detach*

В С++14 можно рахделять большие числа:
```cpp
constexpr auto tenMillion = 10`000`000;
```

```cpp
constexpr auto tenMillion = 10`000`000;

bool doWork (std::function <bool (int)> filter,
             int maxVal = tenMillion)
{
    std::vector <int> goodVals;
    std::thread thread (
        [&filter, maxVal, &goodVal]
        {
            for (auto i = 0; i <= maxVal; ++i) {
                if (filter (i))
                    goodVals.push_back (i);
            }
        });
        
    auto nh = thread.native_handle ();
    
    if (conditionsAreSatisfied ()) {
        thread.join ();
        performComputation (goodVals);
        return true;
    }
    
    return false;    // Ошибка!!! Завершение программы!!!
}
```

При вызове деструктора из подключаемого объекта программа завершает свою работу, поэтому с *std::thread* нужно быть аккуратным.

*RAII* (*Resource Acquisition Is Initialization*) - *захват ресурса есть инициализация* (На самом деле речь идёт о методе деструкции). Примеры: контейнеры STL, стандартные интеллектуальные указатели, объекты *std::fstream*. Но нет стандартного *RAII* класса для *std::thread*. Напишем его сами:
```cpp
class ThreadRAII {
public:
    enum class DtorAction { join, detach };
    
    ThreadRAII (std::thread&& thread, // Т.к. std::thread не копируется
                DtorAction action) :
        thread (thread),
        action (action)
    {}
    
    ~ThreadRAII () {
        if (thread.joinable ()) {
            if (action == DtorAction::join)
                thread.join ();
            else
                thread.detach ();
        }
    }
    
    ThreadRAII (ThreadRAII&&) = default;            // Поддержка перемещающих
    ThreadRAII& operator= (ThreadRAII&&) = default; // операций
    
    std::thread& get () {    // Чтобы не дублировать интерфейс std::thread
        return thread;
    }
    
private:
    DtorAction action;
    std::thread thread; // Объявлять потоки в конце хорошая привычка
};
```

Тогда наш предыдущий код можно записать следующим образом:
```cpp
bool doWork (std::function <bool (int)> filter,
             int maxVal = tenMillion)
{
    std::vector <int> goodVals;
    
    ThreadRAII thread (
        std::thread (
            [&filter, maxVal, &goodVal]
            {
                for (auto i = 0; i <= maxVal; ++i) {
                    if (filter (i))
                        goodVals.push_back (i);
                }
            }),
        ThreadRAII::DtorAction::join
    );
        
    auto nh = thread.get().native_handle ();
    
    if (conditionsAreSatisfied ()) {
        thread.get().join ();
        performComputation (goodVals);
        return true;
    }
    
    return false;    // Ошибка!!! Завершение программы!!!
}
```

Но что, если *join* будет приводить к зависанию программы? Чтобы справиться с этим, нужны *прерываемые потоки*. Увы, С++11 их е поддерживает.

### <center>Следует запомнить</center>
* Делайте *std::thread* неподключаемым на всех путях выполнения.
* Применение *join* при уничтожении объекта может привести к трудно отлаживаемым аномалиям производительности.
* Применение *detach* при уничтожении объекта может привести к трудноотлавливаемому неопределённому поведению.
* Объявляйте объекты *std::thread* в списке членов-данных последними.

## 7.4 Помните о разном поведении деструкторов дескрипторов потоков

Объекты *std::thread* и объекты фьючерсов можно рассматривать как *дескрипторы* (*handles*) системных потоков.
```cpp
// | Вызывающая |     фьючерс    std::promise (обычно) | Вызываемая |
// | функци     | <----------------------------------- | функция    |
```

Где хранится результат вызываемой функции, если мы используем *std::async*? Он не может храниться ни в объектах вызываемой функции, ни в объектах вызывающей функции. Он должен хранится где-то вне их. Это место называется *общее состояние* (*shared state*). 
```cpp
//                               Общее состояние
// | Вызывающая |     фьючерс     | Результат |  std::promise (обычно) | Вызываемая |
// |   функци   | <-------------- |  вызова   | <--------------------- | функция    |
```

Для поведения деструктора фьючерса справедливо следующее:
* Деструктор последнего фьючерса, ссылающегося на общее состояние для неотложенной задачи, запущенной с помощью *std::async*, блокируется до тех пор, пока задача не будет завершена.
* Деструкторы всех прочих фьючерсов просто уничтожают объект фьючерса.








































































